# -*- coding: utf-8 -*-
"""IR4PlagDetect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BuNaNrlDV3Z87ZHkt2jURYK8zh-E9Jt4
"""

import nltk
nltk.download('stopwords')
nltk.download('punkt_tab')

import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def preprocess(text):
    """Preprocesses text by tokenizing, removing stop words, and stemming."""
    words = nltk.word_tokenize(text)
    words = [word.lower() for word in words]
    words = [word for word in words if word not in stopwords.words('english')]
    stemmer = PorterStemmer()
    words = [stemmer.stem(word) for word in words]
    return " ".join(words)

def build_index(corpus):
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(corpus)
    return X, vectorizer

def calculate_similarity(test_doc, index, vectorizer):
    test_vec = vectorizer.transform([preprocess(test_doc)])
    similarity_scores = cosine_similarity(test_vec, index)
    return similarity_scores

def detect_plagiarism(similarity_scores, threshold=0.8):
    plagiarized_docs = []
    for i, score in enumerate(similarity_scores[0]):
        if score > threshold:
            plagiarized_docs.append(i)
    return plagiarized_docs

def rank_documents(similarity_scores):
    ranked_indices = np.argsort(similarity_scores[0])[::-1]
    return ranked_indices

def main():
    # Read the training corpus from file_info.csv
    train_df = pd.read_csv('/content/drive/MyDrive/data/file_information.csv')
    train_corpus = train_df['File'].tolist()
    preprocessed_train_corpus = [preprocess(doc) for doc in train_corpus]

    # Build the index for the training corpus
    index, vectorizer = build_index(preprocessed_train_corpus)

    # Read the test documents from test_info.csv
    test_df = pd.read_csv('/content/drive/MyDrive/data/test_info.csv')
    test_docs = test_df['File'].tolist()

    for test_doc in test_docs:
        preprocessed_test_doc = preprocess(test_doc)
        similarity_scores = calculate_similarity(preprocessed_test_doc, index, vectorizer)
        plagiarized_docs = detect_plagiarism(similarity_scores)
        ranked_indices = rank_documents(similarity_scores)

        print("For test document:", test_doc)
        print("Plagiarized documents:", plagiarized_docs)
        print("Ranked documents by similarity:")
        for i in ranked_indices:
            print(train_df['File'][i])
        print()

if __name__ == "__main__":
    main()

from google.colab import drive
drive.mount('/content/drive')